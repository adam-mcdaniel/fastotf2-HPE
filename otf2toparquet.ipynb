{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a9c354",
   "metadata": {},
   "source": [
    "Copyright Hewlett Packard Enterprise Development LP.\n",
    "\n",
    "\n",
    "# Convert OTF2 to Parquet with Timing\n",
    "This notebook demonstrates how to convert OTF2 data to Parquet format while measuring the execution time for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aabf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import otf2\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1b62063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper Functions\n",
    "def safe_dict(obj):\n",
    "    if isinstance(obj, otf2.definitions.MetricClass):\n",
    "        return {\n",
    "            \"members\": [str(member) for member in obj.members]\n",
    "        }\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        return {key: str(value) for key, value in vars(obj).items()}\n",
    "    elif hasattr(obj, '_asdict'):\n",
    "        return {key: str(value) for key, value in obj._asdict().items()}\n",
    "    else:\n",
    "        return {attr: str(getattr(obj, attr)) for attr in dir(obj) if not attr.startswith('_') and not callable(getattr(obj, attr))}\n",
    "\n",
    "def generate_location_hash(location_name):\n",
    "    return hashlib.md5(location_name.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465af942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OTF2 Data\n",
    "def read_otf2_data(archive_name):\n",
    "    start_time = time.time()\n",
    "    data = {'events': [], 'definitions': []}\n",
    "    with otf2.reader.open(archive_name) as trace:\n",
    "        defs = trace.definitions\n",
    "        eves = trace.events\n",
    "        # Measure time taken to open the OTF2 archive\n",
    "        open_end = time.time()\n",
    "        print(f\"Time taken to open OTF2 archive: {open_end - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "        for def_type in dir(trace.definitions):\n",
    "            if def_type.startswith('_') or def_type == 'attribute':\n",
    "                continue\n",
    "            definitions = getattr(trace.definitions, def_type)\n",
    "            if callable(definitions):\n",
    "                continue\n",
    "            try:\n",
    "                iterator = iter(definitions)\n",
    "            except TypeError:\n",
    "                data['definitions'].append(safe_dict(definitions))\n",
    "            else:\n",
    "                for definition in definitions:\n",
    "                    data['definitions'].append(safe_dict(definition))\n",
    "\n",
    "        dict_start_time = time.time()\n",
    "        for location, event in trace.events:\n",
    "            event_info = safe_dict(event)\n",
    "            event_info['location'] = location.name\n",
    "            event_info['location_hash'] = generate_location_hash(location.name)\n",
    "            if isinstance(event, otf2.events.Enter):\n",
    "                event_info['event'] = 'Enter'\n",
    "                event_info['region'] = event.region.name\n",
    "            elif isinstance(event, otf2.events.Leave):\n",
    "                event_info['event'] = 'Leave'\n",
    "                event_info['region'] = event.region.name\n",
    "            data['events'].append(event_info)\n",
    "        dict_end_time = time.time()\n",
    "        print(f\"Time taken to build dictionary for event: {dict_end_time - dict_start_time:.2f} seconds\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to read OTF2 data: {end_time - start_time:.2f} seconds\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8ec218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data to Parquet\n",
    "def convert_to_parquet(data, definitions_file, events_file):\n",
    "    start_time = time.time()\n",
    "    df_definitions = pd.DataFrame(data['definitions'])\n",
    "\n",
    "    for col in df_definitions.select_dtypes(include=['object']).columns:\n",
    "        df_definitions[col] = df_definitions[col].astype(str)\n",
    "\n",
    "    df_definitions.to_parquet(definitions_file)\n",
    "    # print(\"Definitions table:\")\n",
    "    # display(df_definitions)\n",
    "\n",
    "    df_events = pd.DataFrame(data['events'])\n",
    "\n",
    "    for col in df_events.select_dtypes(include=['object']).columns:\n",
    "        df_events[col] = df_events[col].astype(str)\n",
    "\n",
    "    df_events.to_parquet(events_file)\n",
    "    # print(\"Events table:\")\n",
    "    # display(df_events)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to convert data to Parquet: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to open OTF2 archive: 0.02 seconds\n",
      "Time taken to build dictionary for event: 137.05 seconds\n",
      "Time taken to read OTF2 data: 137.10 seconds\n",
      "Time taken to convert data to Parquet: 110.80 seconds\n",
      "Total execution time: 260.04 seconds\n"
     ]
    }
   ],
   "source": [
    "# archive_name = \"/workspace/scorep-traces/simple-mi300-example-run/traces.otf2\"\n",
    "archive_name = \"/workspace/scorep-traces/frontier-hpl-run-using-2-ranks-with-craypm/traces.otf2\"\n",
    "definitions_file = \"definitions.parquet\"\n",
    "events_file = \"events.parquet\"\n",
    "\n",
    "start_time = time.time()\n",
    "data = read_otf2_data(archive_name)\n",
    "\n",
    "convert_to_parquet(data, definitions_file, events_file)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebe3aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Event Summary:\n",
      "Total number of events: 16613424\n",
      "Event types and their counts:\n",
      "  Unknown: 2633870 events\n",
      "  Enter: 6989777 events\n",
      "  Leave: 6989777 events\n",
      "Unique locations:\n",
      "  \n",
      "  HIP[0:1]\n",
      "  HIP[3:0]\n",
      "  HIP[1:2]\n",
      "  HIP[2:0]\n",
      "  HIP[3:1]\n",
      "  HIP[3:2]\n",
      "  HIP[0:3]\n",
      "  HIP[2:1]\n",
      "  Master thread\n",
      "  Per process metrics\n",
      "  HIP[0:2]\n",
      "  HIP[2:3]\n",
      "  HIP[2:2]\n",
      "  HIP[1:0]\n",
      "  HIP[1:3]\n",
      "  HIP[0:0]\n",
      "  HIP[1:1]\n",
      "  HIP[3:3]\n"
     ]
    }
   ],
   "source": [
    "# Count and describe events\n",
    "event_counts = {}\n",
    "for event in data['events']:\n",
    "    event_type = event.get('event', 'Unknown')\n",
    "    event_counts[event_type] = event_counts.get(event_type, 0) + 1\n",
    "\n",
    "total_events = len(data['events'])\n",
    "print(\"\\nEvent Summary:\")\n",
    "print(f\"Total number of events: {total_events}\")\n",
    "print(\"Event types and their counts:\")\n",
    "for event_type, count in event_counts.items():\n",
    "    print(f\"  {event_type}: {count} events\")\n",
    "\n",
    "\n",
    "print(\"Unique locations:\")\n",
    "unique_locations = set(event.get('location', 'Unknown') for event in data['events'])\n",
    "for location in unique_locations:\n",
    "    print(f\"  {location}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f9372",
   "metadata": {},
   "source": [
    "Timing from Reading craypm trace with default batch size (100):\n",
    "\n",
    "```\n",
    "Time taken to open OTF2 archive: 0.02 seconds\n",
    "Time taken to build dictionary for event: 131.27 seconds\n",
    "Time taken to read OTF2 data: 131.32 seconds\n",
    "\n",
    "Event Summary:\n",
    "Total number of events: 16613424\n",
    "Event types and their counts:\n",
    "  Unknown: 2633870 events\n",
    "  Enter: 6989777 events\n",
    "  Leave: 6989777 events\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284934f6",
   "metadata": {},
   "source": [
    "Timing with batch size equal to num events (16613424):\n",
    "\n",
    "```\n",
    "Time taken to open OTF2 archive: 0.02 seconds\n",
    "Time taken to build dictionary for event: 156.49 seconds\n",
    "Time taken to read OTF2 data: 156.54 seconds\n",
    "\n",
    "Event Summary:\n",
    "Total number of events: 16613424\n",
    "Event types and their counts:\n",
    "  Unknown: 2633870 events\n",
    "  Enter: 6989777 events\n",
    "  Leave: 6989777 events\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28624314",
   "metadata": {},
   "source": [
    "Reading Cray PM with Batch size 16613:\n",
    "\n",
    "```\n",
    "Time taken to open OTF2 archive: 0.02 seconds\n",
    "Time taken to build dictionary for event: 246.79 seconds\n",
    "Time taken to read OTF2 data: 246.84 seconds\n",
    "\n",
    "Event Summary:\n",
    "Total number of events: 16613424\n",
    "Event types and their counts:\n",
    "  Unknown: 2633870 events\n",
    "  Enter: 6989777 events\n",
    "  Leave: 6989777 events\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e569b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkouda-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
